{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"belajar_natural_language_processing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VwK5-9FIB-lu"},"source":["# Natural Language Processing"]},{"cell_type":"markdown","source":["Natural language processing digunakan untuk chatbots, speak recognition, search engine, translate dan masih banyak lagi. contoh metode NLP adalah bag-of-words, seperti yang akan diimplementasikan kode di bawah\n","NLP yang bersinggunakan dengan deep learning adalah deep learning NLP (DNLP), menggunakan neural network untuk memahami bahasa natural. sub disiplin DNLP adalah seq2seq"],"metadata":{"id":"dG9ZrKqDqMfs"}},{"cell_type":"markdown","source":["##Bag of words"],"metadata":{"id":"nMvQMw-drjoS"}},{"cell_type":"markdown","source":["Bag of words pada dasarnya memplot tiap kata ke dalam suatu vektor, sehingga tiap element dari vektor tersebut merepresentasikan jumlah spesifik kata dalam suatu kalimat. vektor tersebut memiliki panjang yang sama dengan jumlah kata yang berbeda dari seluruh kalimat. Jika dipadankan dengan klasifikasi vektor tersebut merupakan input.\n","\n","contohnya adalah sebagai berikut:\n","\n","Review 1: This movie is very scary and long\n","\n","Review 2: This movie is not scary and is slow\n","\n","Review 3: This movie is spooky and good\n","\n","bisa dilihat bahwa vector mencakup seluruh kata yang berbeda dari seluruh kalimat"],"metadata":{"id":"FtCa1bkkrmT3"}},{"cell_type":"markdown","source":["![BoWBag-of-Words-model-2.webp](data:image/webp;base64,UklGRtgLAABXRUJQVlA4TMwLAAAvvcIpAGegNJIkNXiKJN+/YqWRJKnBUyT5/hUrjSRJDZ4iyfeveP4DAK61dDcRce/FzMYYzIyqGmNARHNO/3/wbP3/S9vatv00muZEwZmTM2yClZOCFUrn6QybYOWkfqZRcOZkI6ycFJz5POdUoNEMje9W9a7//fw7c/7PHNF/Wowk2W2kFNDA1L6KwyZNDrvFu1/8h8Pn5gcqG0/cbt7tt/vNp1updm753mVO1DGn93rcbDkIJXg8bhrdHM4vcHMQjheuxO1VKINLauoA1N5VEuJw4F6GMYpxWxFhBfgNA0WSpeBfoGaymJySOtEzmPRNoncDrTih0UTUg+hPnp7BoU5NZFlYg3mHJq3M/PYUaPYAvwmri3ByVAdlonKyPjt/9qC/WcXNYqAB1pAngoH+ZoZPq5ysE535XeZ3S+ZV3iDyVE7WZ9QnPiYCmwxQO3nBtxrAb5a4rd+cCaszdwJA2WSTopToznnnEbU5vbugJsKZkv50YrIpuVYIE64z8lhmagpYbqyIR0rUsezoNHIoiWjm4FDFIif2VMFq4VPDxakAo9+4M8Imj6ScY+VSU8LMQAdGz8kxF8bA8fgAczLiCuDgN9yJqHlZ5IHnxhqMkTlXIbXQmFaBlCq4JOKGhd+kye7WOtIXuQBWxzyEewZpJg6bsUdu7qUJx08dQGN51Ge756ai3ZYR9Im3Zf6XKnzJ2kpNNOzvh3jKx+x5aBMD91dbWdsajZi4Dcu7/lDGxOm4c+W0eQKDmzh+BVj9AVfqNhyHNHO85JRxzBg5F6KRY8cY7I6H2bOIqWVhjiLrgGyOs84sIfgFeMFq153UCf8HkVOxGN2W51GbeZn1JvFOzUTyAvYZdoI2MnGbdXLiXpoAYcHBPMG7CglYk5In0CdentoDm7NszNcdHEYOC7B4ElbH8cgdhHBYVyd2Zw0swoxHBA08NPABIcA9RU6JMp4xm6hiyaLrbQnURCw7OSVgYbe8STGpYmFRyz4JEnUOtUx8osYiGuSmOayR1PMZX5qJ0OGx5GNzy+ZedDMu41MLTxGKttYhvOyiWadPAlivJNDpbgB9tn6VgNKCmtWgZPUVNQ1h5bfarL+RLAyARvON4oRXRioo1x6cLi3M0UuThYE7Qa/HZ5I6UBlZLkSF/U6SJgsDv3qxjS7wVEaWHAA/Ks4B8J99N8suUULZWxSrpNSmJxmIvdFr0owH5EJA7W3IQKtfc0S7kY1J5MEcJG8BSQhlsNG4xg7QqC1pSJOzgZxmvcuT64aaiIozwRaGNTwZslRu2dyKiYtlHl6JWx4Hut62etBh5Hsz0JdcRRZgnI86KkTX9VpmJvCpcJs6sPqYipUzwooNEJzOoc5/6PsJzFF0OFbQI+g0m+ZnG3iX21lTgAfMCA6tEVOCyEhgkSci/Cl1MGjQqRFhEwgONU4XVrloUcKmxfaElJ0nrAziSIPbCiiJmgtPsAINMtOeuaYqmVG/68WVf5kPNU006LMG/dtZmli9MelieelQ4MQYzb8GZeIH8KAJH0U+FVbhU6PTmVWa5cklDsxRG4xJK2lFNiZzPG9/EjYQmY/SLC5OujiPPl32VAfw/MbN0mKx/Rd2tM4Y9dmYNOifBHZnjpboYHR7Y77wdDdI6RgrdaKBcccLEwjwoM3G7xJY70dhZfUerFFImECM3S/qkvzq5D4SbJCfLa6u4LbmUAdxJZoHa9Bm88NobfDXAE5HMH5XpJUwFHnidHWwMqAJdDJivFE4z4aNAJqgzfa7EexfnCcs8OB0xiw61kbr4wtPr2RyB9iFbPz9NIjW+M2JgdzO6olIDCgS4zZBSuSdsF8qIBokJ0qiE9CdTvhY6sz7bD5MwnaFiIFN44KPk8e/4PYCbBpPvHMJeQirAAKc3iiFHCOscPkMaA3DGM5h5Ry/+rQojpI0A074XiPO7hNu556xtOHSjjVa2/g70bwZOO2C6YHnbPEJ2WlXgtHnXiLCpULM9Z/xXYFwNuaVMHrQYNN8lgHhYOFQ5KSkqg4WpMLaBR96WMWf6uwzLs2XmKNxZqBV+Xw+PvGa4LnBJWF1/mWhmdZvqYzqAMZP3Yvsv7Cj9caoQZ89aGXgFiDhRlgTIPCU0gFDSRnWcKiBG8DqQyIxS4ciJ9TBpuRETZNgg3IqoCUpBWfiAJf4pC+wyVr5Yz4VODESNWsBGk0Q/zGTZoJFHawqDESYNGtGApcqONSUQe7B6ERufaL5whPMwJBFHXCKba6SEPu53ib24Zom8g7tuCoDrvdNeXrDfsJtDsJkmBzxYyuppNn1wu4+ecTGrxbbKYWwyqMrADbaLMKYWAUZkqijq8n7C2HGtmy3EtOIqL/Gkc6l9MSZRYGcOV7eI5XkwTB7IwpqqvBpVtg1V1zrkJZ7Vxxszm45LO+R7N7pjCZPwiBsnoI+A1DBdWYASBf3SPocVsYYVnXgZ4AxcWRl62UuF/dIImpKTqhkfcXiHkkEQKegkPLyHska7N4Y05PsQ1dLeXmPlFK0aFJKHljclUGp5OtcdCubLIk0g+LIV8dvoG6yrL2jPPJePz+4UdiolDLwz4JMKilfkhNVl3j36+vtfYc0qUlp5TSBNtvUG2NYEc4GJrv3G3WU06T2yijP7M5p6WzAGszW7dRRTon6uEDgN9ZAZwNu93BlDyop+0VMFMSZMdPZQNi8lZmzSsrlonapjDycA/KsevazUEkZ2icRAC3BSQZqr/1CAvWThZi9RRmMCoSzAa23C6ihLHGa/Yr/pQE8nJaFxv/mBh7mwPNYe7xJ8alleSwp4RNTtSGbSkqk4RBVu0mIvOAS/5RH/FMWls0kL3hz4z7K5HNf4vEQHmLhjM7IxoS5yppdeTsn7fYT6oq9v1uJbhxuqJkhZIIVRMbtmcOjiPmz/lO44xob7G7EHTedY6/HzQZuGNywgVTAQ3waaeBMHDvPIW3Z2V/Av+jO49qVF76wTT4I+w4i3OnSo5h8C+EKtyvkEsmu/8P4cOBqOALkhTWuFfIG900ZTLnfIk9rbLC7DX/AfVHG03iW5caenImd/Z+7PFuz7UoLFvYTcqKKR0wkPoSFbjh/0dq3poq3iINLNLByzyAPPJMdy2NOGdiE1GzI7pwySONpSJeFLUAKudYhTGwhCrjWweFFXYSarnXsEenhfjPAOoorQ1dcGf/ilXWiWW1lQHFlQCFlxawr/r//PR3/8dfTUVLCIaaKuf8Mmnfa0wFz2HtPB4hw0J4Of7YnBiZMHmmTNrvq6VizvvOeDn+ID9vTAX/c2khxK3aY7bSnA+GAnfd0+GPaHbWuGO5l4DdSiB0+v6uejjV23tORF9a8Keybh8Fh5UgQ8+KuejrW2HtPh33gno6Gh8/m+T30dLDZeU9H2PmHla2Z20jBlYtd9HRw5Z33dNioq4PKaSPwKKGRIm7Tdlc9HWth5z0dzpg2B+3pcIlaBiE1zHzSCTvr6RBb33lPR040S5ZdapX2GV/dxJHi1rblgQA1XetIo/0hPdxfBqxfqJRWBrRJbWU/g9rK+gSllUv6r7Kejh/cqmz8V7RMKilvbTpQytq2mpRV3tR0oIZ1xZuaDtRP3tx0oH7y5qYDNZQ3NR2oobyp6UD95K1NBwq4znyQFzrwK/3ZTQfM0n920wFYTQeQ9EIHaJseBpmDvGDT9Sszr/lCB7lNByLEpf97fqGDZc8bstt9VB5ltYMfxjv41mu5TQerpf+7eKEDf5KdLSCURzjiHvCd7bLLtm/FxdP7+kp8XA1swtVourq8q1CsTNhK0wGPvJXa0+Ey35eRt9ICrhTcrXXFB+HoYecDd6qr48uSmg6Ycr+LFzrsHH+sq4PLjEp/EeymA3HpvwSETQcC1roHdi7H7cbOu4O80IFf6c9uOmD+hxmzmw7AajqApBc6WJuqoFyiQdqpRfMgOTjUSdntN1LPczf3jLvFm6tl982+Fq+aWLTEcZ9d6zhOVbzq9nT4hdrWV1g0qq2M3PsX6ndXMii7PFBduVPeumLVlaGSMhOVlJmopKy+/19v/9n7AQ==)"],"metadata":{"id":"Lj5G0iFxvIyr"}},{"cell_type":"markdown","source":["Sebelum training kalimat premis akan dihitung jumlah kata spesifik (pada contoh diatas review 2 mengandung this 1 kali, movie 1 kali serta is 2 kali, dan seterusnya) Masukkan jumlah tiap kata spesifik ini ke dalam suatu vektor (tiap element vektor merepresentasikan kata yang berbeda, sehingga memasukkan jumlah tiap kata spesifik harus sesuai dengan apa yang direpresentasikan elemen tersebut). Proses ini akan dilakukan pada setiap kalimat.\n","\n","setelah menentukan jumlah kata spesifik pada setiap kalimat, akan dilakukan training dengan klasifikasi. setiap kalimat training terdapat kesan/action (pada contoh yang akan dibahas di bawah setiap kalimat merupakan review restoran dan mepresentasikan positif/suka atau negatif/tidak suka pada restoran tersebut). Karena tiap kalimat premis sudah dijadikan vektor dan vektor merupakan input untuk klasifikasi, maka kita haya perlu mentrain dengan klasifikasi dengan inputnya adalah vektor dan outputnya adalah action"],"metadata":{"id":"99SpW-gYvLsb"}},{"cell_type":"markdown","metadata":{"id":"X1kiO9kACE6s"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"7QG7sxmoCIvN","executionInfo":{"status":"ok","timestamp":1652432132703,"user_tz":-420,"elapsed":424,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wTfaCIzdCLPA"},"source":["## Importing the dataset"]},{"cell_type":"code","source":["dataset = pd.read_csv('Restaurant_Reviews.tsv',sep='\\t')\n","y=dataset.iloc[:,1].values"],"metadata":{"id":"6b4qhFZ-neJN","executionInfo":{"status":"ok","timestamp":1652432133251,"user_tz":-420,"elapsed":5,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qekztq71CixT"},"source":["## Cleaning the texts"]},{"cell_type":"code","source":["import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","clean_texts = []\n","for i in range(0,dataset.shape[0]):\n","  review=dataset.iloc[i,0]\n","  review=re.sub('[^a-zA-Z]',' ',review)\n","  review=review.lower()\n","  review=review.split()\n","  all_stopwords = stopwords.words('english')\n","  all_stopwords.remove('not')\n","  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n","  review = ' '.join(review)\n","  clean_texts.append(review)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy4F0g6DoZM0","executionInfo":{"status":"ok","timestamp":1652432134659,"user_tz":-420,"elapsed":1412,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}},"outputId":"ed3694d3-89f0-475f-e3a6-825f3ee3c914"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["Untuk mengefiensikan resource, maka tiap kalimat diharapkan menghilangkan stopwords (e.g. the,is,it,.) karena kata-kata tersebut kurang penting dan tidak akan berpengaruh pada kesan/action dari kalimat, sehingga dapat mengurangi panjangnya vektor. Untuk meningkatkan keefektifan prediksi, maka tiap kata harus di-stemming. Inti dari stemming adalah mengembalikan kata menjadi kata asalnya. contohnya adalah kata programming diubah menjadi program, kata clearly menjadi clear, dan sebagainya. Alasan mengapa harus begitu adalah agar kata turunan dan kata akar tidak dianggap 2 kata yang berbeda. contohnya adalah jika programming tidak di stem menjadi program, maka 2 kata tersebut dianggap berbeda, padahal memiliki kesan/makna yang sama"],"metadata":{"id":"p7grr2Eu5s9S"}},{"cell_type":"markdown","source":["stopwords dianggap adalah kata-kata yang tidak dianggap penting, namun berbeda dengan stopword not, kata not dapat memberikan kesan negatif, oleh karena itu kita harus menghapus string not dari stopwords"],"metadata":{"id":"bgkx4kwL-Cqm"}},{"cell_type":"markdown","metadata":{"id":"CLqmAkANCp1-"},"source":["## Creating the Bag of Words model"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","bw = CountVectorizer()\n","X=bw.fit_transform(clean_texts).toarray()\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOGq14H0q6hD","executionInfo":{"status":"ok","timestamp":1652432134660,"user_tz":-420,"elapsed":22,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}},"outputId":"c8ef9db4-fcb0-4395-fe67-f583118aa006"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       ...,\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 0, 0, 0]])"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"DH_VjgPzC2cd"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)"],"metadata":{"id":"qke4H_qJkTYG","executionInfo":{"status":"ok","timestamp":1652432134661,"user_tz":-420,"elapsed":9,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VkIq23vEDIPt"},"source":["## Training the Naive Bayes model on the Training set"]},{"cell_type":"code","source":["from sklearn.naive_bayes import GaussianNB\n","classifier = GaussianNB()\n","classifier.fit(X_train,y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DEUV0Mx_lKNX","executionInfo":{"status":"ok","timestamp":1652432134661,"user_tz":-420,"elapsed":9,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}},"outputId":"e38cc9d4-a7f3-4d8c-f9b8-ed36b89677ef"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GaussianNB()"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"1JaRM7zXDWUy"},"source":["## Predicting the Test set results"]},{"cell_type":"code","source":["y_pred=classifier.predict(X_test)"],"metadata":{"id":"_VhSd1nZloYH","executionInfo":{"status":"ok","timestamp":1652432134661,"user_tz":-420,"elapsed":7,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xoMltea5Dir1"},"source":["## Making the Confusion Matrix"]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,accuracy_score\n","print(confusion_matrix(y_test,y_pred))\n","accuracy_score(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeKG-M1Nl5fe","executionInfo":{"status":"ok","timestamp":1652432134661,"user_tz":-420,"elapsed":7,"user":{"displayName":"haris prasetyo","userId":"08181596121714717161"}},"outputId":"d6acdaa8-a4b0-43c5-b544-de21383f2395"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 67  50]\n"," [ 20 113]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.72"]},"metadata":{},"execution_count":61}]}]}